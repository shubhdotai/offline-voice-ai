<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech Detection with Transcription</title>
    <style>
        body {
            font-family: 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0;
            padding: 20px;
            box-sizing: border-box;
        }
        
        .container {
            background: white;
            padding: 40px;
            border-radius: 20px;
            text-align: center;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            min-width: 450px;
            max-width: 700px;
            width: 100%;
        }
        
        h1 {
            color: #333;
            margin-bottom: 30px;
        }
        
        .state {
            font-size: 2.5em;
            font-weight: bold;
            margin: 20px 0;
            padding: 20px;
            border-radius: 15px;
            min-height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
        }
        
        .state.quiet { 
            background: #f5f5f5; 
            color: #666; 
            border: 2px solid #ddd;
        }
        
        .state.starting { 
            background: #fff3cd; 
            color: #856404; 
            border: 2px solid #ffeaa7;
            animation: pulse 1.5s ease-in-out infinite;
        }
        
        .state.speaking { 
            background: #d4edda; 
            color: #155724; 
            border: 2px solid #4CAF50;
            box-shadow: 0 0 20px rgba(76, 175, 80, 0.3);
        }
        
        .state.stopping { 
            background: #f8d7da; 
            color: #721c24; 
            border: 2px solid #f5c6cb;
            animation: fadeOut 1s ease-in-out infinite alternate;
        }
        
        @keyframes pulse {
            0%, 100% { transform: scale(1); opacity: 0.8; }
            50% { transform: scale(1.05); opacity: 1; }
        }
        
        @keyframes fadeOut {
            0% { opacity: 1; }
            100% { opacity: 0.6; }
        }
        
        .transcript-container {
            background: #f8f9fa;
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            min-height: 120px;
            text-align: left;
            border: 2px solid #e0e0e0;
            max-height: 300px;
            overflow-y: auto;
        }
        
        .transcript-label {
            font-size: 14px;
            color: #666;
            font-weight: bold;
            margin-bottom: 10px;
            text-transform: uppercase;
        }
        
        .transcript-text {
            font-size: 18px;
            line-height: 1.6;
            word-wrap: break-word;
            color: #333;
            white-space: pre-wrap;
        }
        
        .metrics {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
            gap: 15px;
            margin: 20px 0;
            text-align: center;
        }
        
        .metric {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 10px;
            border-left: 4px solid #667eea;
        }
        
        .metric-label {
            font-size: 12px;
            color: #666;
            text-transform: uppercase;
            margin-bottom: 5px;
        }
        
        .metric-value {
            font-size: 18px;
            font-weight: bold;
            color: #333;
        }
        
        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin: 30px 0;
            flex-wrap: wrap;
        }
        
        button {
            padding: 15px 25px;
            border: none;
            border-radius: 25px;
            font-size: 16px;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.2s;
            min-width: 120px;
        }
        
        button:hover:not(:disabled) { 
            transform: translateY(-2px); 
            box-shadow: 0 4px 12px rgba(0,0,0,0.2);
        }
        
        button:disabled { 
            opacity: 0.5; 
            cursor: not-allowed; 
            transform: none; 
        }
        
        .start { background: #4CAF50; color: white; }
        .stop { background: #f44336; color: white; }
        .reset { background: #ff9800; color: white; }
        
        .connection {
            position: fixed;
            top: 20px;
            right: 20px;
            padding: 8px 16px;
            border-radius: 15px;
            font-weight: bold;
            font-size: 14px;
            z-index: 1000;
        }
        
        .connected { background: #4CAF50; color: white; }
        .disconnected { background: #f44336; color: white; }
        
        .listening-indicator {
            position: fixed;
            top: 20px;
            left: 20px;
            padding: 8px 16px;
            border-radius: 15px;
            font-weight: bold;
            font-size: 14px;
            background: #f44336;
            color: white;
            z-index: 1000;
            display: none;
        }
        
        .listening-indicator.active {
            display: block;
            animation: listeningBlink 1s ease-in-out infinite alternate;
        }
        
        @keyframes listeningBlink {
            0% { opacity: 1; }
            100% { opacity: 0.5; }
        }

        .protocol-indicator {
            position: fixed;
            bottom: 20px;
            right: 20px;
            padding: 6px 12px;
            border-radius: 12px;
            font-size: 12px;
            background: #667eea;
            color: white;
            z-index: 1000;
        }
    </style>
</head>
<body>
    <div class="connection" id="connection">Disconnected</div>
    <div class="listening-indicator" id="listeningIndicator">üé§ LISTENING</div>
    <div class="protocol-indicator">‚ö° Binary Protocol</div>
    
    <div class="container">
        <h1>üé§ Speech Detection & Transcription</h1>
        
        <div class="state quiet" id="stateDisplay">üîá QUIET</div>
        
        <div class="transcript-container">
            <div class="transcript-label">üìù Transcriptions</div>
            <div class="transcript-text" id="transcriptDisplay">
                <em style="color: #999;">Transcriptions will appear here...</em>
            </div>
        </div>
        
        <div class="metrics">
            <div class="metric">
                <div class="metric-label">Current VAD</div>
                <div class="metric-value" id="currentProb">0.000</div>
            </div>
            <div class="metric">
                <div class="metric-label">Smoothed VAD</div>
                <div class="metric-value" id="smoothedProb">0.000</div>
            </div>
            <div class="metric">
                <div class="metric-label">Speech Segments</div>
                <div class="metric-value" id="segmentCount">0</div>
            </div>
            <div class="metric">
                <div class="metric-label">Last Latency</div>
                <div class="metric-value" id="lastLatency">-</div>
            </div>
            <div class="metric">
                <div class="metric-label">Avg Latency</div>
                <div class="metric-value" id="avgLatency">-</div>
            </div>
        </div>
        
        <div class="controls">
            <button class="start" id="startBtn">Start Listening</button>
            <button class="reset" id="resetBtn">Reset</button>
        </div>
    </div>

    <script>
        let ws = null;
        let audioContext = null;
        let isListening = false;
        let isActive = false;
        
        const stateDisplay = document.getElementById('stateDisplay');
        const startBtn = document.getElementById('startBtn');
        const connection = document.getElementById('connection');
        const listeningIndicator = document.getElementById('listeningIndicator');
        const currentProb = document.getElementById('currentProb');
        const smoothedProb = document.getElementById('smoothedProb');
        const segmentCount = document.getElementById('segmentCount');
        const lastLatency = document.getElementById('lastLatency');
        const avgLatency = document.getElementById('avgLatency');
        const transcriptDisplay = document.getElementById('transcriptDisplay');
        
        let fullTranscript = '';
        let latencies = [];
        let segmentStartTime = null;
        
        // Connect WebSocket
        function connect() {
            const protocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            ws = new WebSocket(`${protocol}//${location.host}/ws`);
            ws.binaryType = 'arraybuffer';
            
            ws.onopen = () => {
                connection.textContent = 'Connected';
                connection.className = 'connection connected';
                console.log('WebSocket connected');
            };
            
            ws.onclose = () => {
                connection.textContent = 'Disconnected';
                connection.className = 'connection disconnected';
                console.log('WebSocket disconnected, reconnecting...');
                setTimeout(connect, 3000);
            };
            
            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
            };
            
            ws.onmessage = (event) => {
                // Server sends JSON responses
                try {
                    const data = JSON.parse(event.data);
                    
                    if (data.events && data.state) {
                        handleStateUpdate(data.state);
                        
                        // Track segment timing
                        if (data.events.includes('speech_stopping')) {
                            segmentStartTime = Date.now();
                        }
                        
                        if (data.transcript) {
                            const latency = segmentStartTime ? Date.now() - segmentStartTime : 0;
                            addTranscript(data.transcript, latency);
                        }
                    } else if (data.listening_started) {
                        isActive = true;
                        listeningIndicator.className = 'listening-indicator active';
                        console.log('Listening started');
                    } else if (data.listening_stopped) {
                        isActive = false;
                        listeningIndicator.className = 'listening-indicator';
                        console.log('Listening stopped');
                    } else if (data.reset) {
                        console.log('System reset');
                    }
                } catch (e) {
                    console.error('Error parsing message:', e);
                }
            };
        }
        
        // Add transcript
        function addTranscript(text, latency) {
            if (!text) return;
            
            // Clear placeholder on first transcript
            if (!fullTranscript) {
                transcriptDisplay.textContent = '';
            }
            
            // Append to continuous transcript with space
            fullTranscript += (fullTranscript ? ' ' : '') + text.trim();
            transcriptDisplay.textContent = fullTranscript;
            
            // Update latency metrics
            if (latency > 0) {
                latencies.push(latency);
                lastLatency.textContent = `${(latency / 1000).toFixed(2)}s`;
                
                const avg = latencies.reduce((a, b) => a + b, 0) / latencies.length;
                avgLatency.textContent = `${(avg / 1000).toFixed(2)}s`;
            }
            
            // Scroll to bottom
            transcriptDisplay.scrollTop = transcriptDisplay.scrollHeight;
        }
        
        // Handle state updates
        function handleStateUpdate(state) {
            updateStateDisplay(state.state);
            currentProb.textContent = (state.current_prob || 0).toFixed(3);
            smoothedProb.textContent = state.smoothed_prob.toFixed(3);
            segmentCount.textContent = state.segments_count;
        }
        
        // Update state display
        function updateStateDisplay(state) {
            const emojis = {
                quiet: 'üîá',
                starting: 'üé§',
                speaking: 'üó£Ô∏è',
                stopping: '‚èπÔ∏è'
            };
            
            stateDisplay.textContent = `${emojis[state] || 'üé§'} ${state.toUpperCase()}`;
            stateDisplay.className = `state ${state}`;
        }
        
        // Start listening
        async function startListening() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: { 
                        sampleRate: 16000, 
                        channelCount: 1,
                        echoCancellation: false,
                        noiseSuppression: false
                    }
                });
                
                audioContext = new AudioContext({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(stream);
                const processor = audioContext.createScriptProcessor(512, 1, 1);
                
                processor.onaudioprocess = (e) => {
                    // ALWAYS send audio chunks, regardless of listening state
                    // This ensures VAD and state machine keep running
                    if (ws?.readyState !== WebSocket.OPEN) return;
                    
                    const samples = e.inputBuffer.getChannelData(0);
                    const buffer = new Float32Array(samples);
                    
                    // Send as binary (more efficient than base64 JSON)
                    ws.send(buffer.buffer);
                };
                
                source.connect(processor);
                processor.connect(audioContext.destination);
                
                isListening = true;
                
                // Send start command
                if (ws?.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({ type: "start_listening" }));
                }
                
                startBtn.textContent = 'Stop Listening';
                startBtn.className = 'stop';
                startBtn.onclick = stopListening;
                
                console.log('Microphone started');
                
            } catch (error) {
                alert('Microphone access required');
                console.error('Microphone error:', error);
            }
        }
        
        // Stop listening
        function stopListening() {
            isListening = false;
            
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            if (ws?.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: "stop_listening" }));
            }
            
            startBtn.textContent = 'Start Listening';
            startBtn.className = 'start';
            startBtn.onclick = startListening;
            
            console.log('Microphone stopped');
        }
        
        // Reset system
        function reset() {
            if (isListening) {
                stopListening();
            }
            
            if (ws?.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: "reset" }));
            }
            
            // Reset UI
            currentProb.textContent = '0.000';
            smoothedProb.textContent = '0.000';
            segmentCount.textContent = '0';
            lastLatency.textContent = '-';
            avgLatency.textContent = '-';
            updateStateDisplay('quiet');
            
            // Clear transcripts
            fullTranscript = '';
            latencies = [];
            segmentStartTime = null;
            transcriptDisplay.innerHTML = '<em style="color: #999;">Transcriptions will appear here...</em>';
            
            console.log('UI reset');
        }
        
        // Initialize
        startBtn.onclick = startListening;
        document.getElementById('resetBtn').onclick = reset;
        
        connect();
    </script>
</body>
</html>