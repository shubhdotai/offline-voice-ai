<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Agent</title>
    <style>
        body {
            font-family: 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0;
            padding: 20px;
            box-sizing: border-box;
        }
        
        .container {
            background: white;
            padding: 40px;
            border-radius: 20px;
            text-align: center;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            min-width: 450px;
            max-width: 700px;
            width: 100%;
        }
        
        h1 {
            color: #333;
            margin-bottom: 30px;
        }
        
        .state {
            font-size: 2.5em;
            font-weight: bold;
            margin: 20px 0;
            padding: 20px;
            border-radius: 15px;
            min-height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
        }
        
        .state.quiet { 
            background: #f5f5f5; 
            color: #666; 
            border: 2px solid #ddd;
        }
        
        .state.starting { 
            background: #fff3cd; 
            color: #856404; 
            border: 2px solid #ffeaa7;
            animation: pulse 1.5s ease-in-out infinite;
        }
        
        .state.speaking { 
            background: #d4edda; 
            color: #155724; 
            border: 2px solid #4CAF50;
            box-shadow: 0 0 20px rgba(76, 175, 80, 0.3);
        }
        
        .state.stopping { 
            background: #f8d7da; 
            color: #721c24; 
            border: 2px solid #f5c6cb;
            animation: fadeOut 1s ease-in-out infinite alternate;
        }
        
        .state.processing { 
            background: #e3f2fd; 
            color: #0d47a1; 
            border: 2px solid #2196F3;
            animation: pulse 1.5s ease-in-out infinite;
        }
        
        @keyframes pulse {
            0%, 100% { transform: scale(1); opacity: 0.8; }
            50% { transform: scale(1.05); opacity: 1; }
        }
        
        @keyframes fadeOut {
            0% { opacity: 1; }
            100% { opacity: 0.6; }
        }
        
        .transcript-container {
            background: #f8f9fa;
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            min-height: 120px;
            text-align: left;
            border: 2px solid #e0e0e0;
            max-height: 300px;
            overflow-y: auto;
        }
        
        .transcript-label {
            font-size: 14px;
            color: #666;
            font-weight: bold;
            margin-bottom: 10px;
            text-transform: uppercase;
        }
        
        .transcript-text {
            font-size: 18px;
            line-height: 1.6;
            word-wrap: break-word;
            color: #333;
            white-space: pre-wrap;
        }
        
        .message {
            margin: 10px 0;
            padding: 10px 15px;
            border-radius: 10px;
        }
        
        .message.user {
            background: #e3f2fd;
            text-align: left;
        }
        
        .message.assistant {
            background: #f1f8e9;
            text-align: left;
        }
        
        .message-label {
            font-weight: bold;
            font-size: 14px;
            margin-bottom: 5px;
        }
        
        .message.user .message-label {
            color: #1976d2;
        }
        
        .message.assistant .message-label {
            color: #558b2f;
        }
        
        .metrics {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 15px;
            margin: 20px 0;
            text-align: center;
        }
        
        .metric {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            border-left: 4px solid #667eea;
        }
        
        .metric-label {
            font-size: 12px;
            color: #666;
            text-transform: uppercase;
            margin-bottom: 8px;
            font-weight: 600;
        }
        
        .metric-value {
            font-size: 24px;
            font-weight: bold;
            color: #333;
        }
        
        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin: 30px 0;
            flex-wrap: wrap;
        }
        
        button {
            padding: 15px 25px;
            border: none;
            border-radius: 25px;
            font-size: 16px;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.2s;
            min-width: 120px;
        }
        
        button:hover:not(:disabled) { 
            transform: translateY(-2px); 
            box-shadow: 0 4px 12px rgba(0,0,0,0.2);
        }
        
        button:disabled { 
            opacity: 0.5; 
            cursor: not-allowed; 
            transform: none; 
        }
        
        .start { background: #4CAF50; color: white; }
        .stop { background: #f44336; color: white; }
        .reset { background: #ff9800; color: white; }
        
        .connection {
            position: fixed;
            top: 20px;
            right: 20px;
            padding: 8px 16px;
            border-radius: 15px;
            font-weight: bold;
            font-size: 14px;
            z-index: 1000;
        }
        
        .connected { background: #4CAF50; color: white; }
        .disconnected { background: #f44336; color: white; }
        
        .listening-indicator {
            position: fixed;
            top: 20px;
            left: 20px;
            padding: 8px 16px;
            border-radius: 15px;
            font-weight: bold;
            font-size: 14px;
            background: #f44336;
            color: white;
            z-index: 1000;
            display: none;
        }
        
        .listening-indicator.active {
            display: block;
            animation: listeningBlink 1s ease-in-out infinite alternate;
        }
        
        @keyframes listeningBlink {
            0% { opacity: 1; }
            100% { opacity: 0.5; }
        }
    </style>
</head>
<body>
    <div class="connection" id="connection">Disconnected</div>
    <div class="listening-indicator" id="listeningIndicator">ðŸŽ¤ LISTENING</div>
    
    <div class="container">
        <h1>ðŸ¤– Voice Agent</h1>
        
        <div class="state quiet" id="stateDisplay">ðŸ”‡ QUIET</div>
        
        <div class="transcript-container">
            <div class="transcript-label">ðŸ’¬ Conversation</div>
            <div class="transcript-text" id="transcriptDisplay">
                <em style="color: #999;">Start speaking to begin conversation...</em>
            </div>
        </div>
        
        <div class="metrics">
            <div class="metric">
                <div class="metric-label">VAD Probability</div>
                <div class="metric-value" id="vadProb">0.000</div>
            </div>
            <div class="metric">
                <div class="metric-label">Speech Segments</div>
                <div class="metric-value" id="segmentCount">0</div>
            </div>
            <div class="metric">
                <div class="metric-label">Status</div>
                <div class="metric-value" id="statusValue">Ready</div>
            </div>
        </div>
        
        <div class="controls">
            <button class="start" id="startBtn">Start Listening</button>
            <button class="reset" id="resetBtn">Reset</button>
        </div>
    </div>
    
    <audio id="audioPlayer" style="display: none;"></audio>

    <script>
        let ws = null;
        let audioContext = null;
        let isListening = false;
        let isActive = false;
        let audioPlayer = document.getElementById('audioPlayer');
        
        const stateDisplay = document.getElementById('stateDisplay');
        const startBtn = document.getElementById('startBtn');
        const connection = document.getElementById('connection');
        const listeningIndicator = document.getElementById('listeningIndicator');
        const vadProb = document.getElementById('vadProb');
        const segmentCount = document.getElementById('segmentCount');
        const statusValue = document.getElementById('statusValue');
        const transcriptDisplay = document.getElementById('transcriptDisplay');
        
        let conversationMessages = [];
        
        // Connect WebSocket
        function connect() {
            const protocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            ws = new WebSocket(`${protocol}//${location.host}/ws`);
            ws.binaryType = 'arraybuffer';
            
            ws.onopen = () => {
                connection.textContent = 'Connected';
                connection.className = 'connection connected';
                console.log('WebSocket connected');
            };
            
            ws.onclose = () => {
                connection.textContent = 'Disconnected';
                connection.className = 'connection disconnected';
                console.log('WebSocket disconnected, reconnecting...');
                setTimeout(connect, 3000);
            };
            
            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
            };
            
            ws.onmessage = async (event) => {
                // Handle binary audio data
                if (event.data instanceof ArrayBuffer) {
                    console.log('Received audio data:', event.data.byteLength, 'bytes');
                    await playAudioResponse(event.data);
                    return;
                }
                
                // Handle text messages
                try {
                    const data = JSON.parse(event.data);
                    
                    if (data.events && data.state) {
                        handleStateUpdate(data.state);
                        
                        if (data.events.includes('processing_started')) {
                            updateStateDisplay('processing');
                            statusValue.textContent = 'Processing';
                        }
                        
                        if (data.transcript) {
                            addMessage('user', data.transcript);
                        }
                        
                        if (data.llm_response) {
                            addMessage('assistant', data.llm_response);
                        }
                        
                        if (data.events.includes('response_complete')) {
                            statusValue.textContent = 'Ready';
                        }
                    } else if (data.listening_started) {
                        isActive = true;
                        listeningIndicator.className = 'listening-indicator active';
                        statusValue.textContent = 'Listening';
                        console.log('Listening started');
                    } else if (data.listening_stopped) {
                        isActive = false;
                        listeningIndicator.className = 'listening-indicator';
                        statusValue.textContent = 'Stopped';
                        console.log('Listening stopped');
                    } else if (data.reset) {
                        statusValue.textContent = 'Ready';
                        console.log('System reset');
                    }
                } catch (e) {
                    console.error('Error parsing message:', e);
                }
            };
        }
        
        // Play audio response
        async function playAudioResponse(audioData) {
            try {
                console.log('Starting audio playback...');
                statusValue.textContent = 'Speaking';
                
                // Create blob from array buffer
                const blob = new Blob([audioData], { type: 'audio/wav' });
                const url = URL.createObjectURL(blob);
                
                // Set up audio player
                audioPlayer.src = url;
                
                // Play audio and wait for completion
                await audioPlayer.play();
                console.log('Audio is now playing...');
                
                // Wait for audio to finish
                await new Promise((resolve) => {
                    audioPlayer.onended = () => {
                        URL.revokeObjectURL(url);
                        resolve();
                    };
                });
                
                // Notify server that audio finished
                if (ws?.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({ type: "audio_finished" }));
                }
                
                statusValue.textContent = 'Ready';
                console.log('Audio playback complete');
                
            } catch (error) {
                console.error('Error playing audio:', error);
                statusValue.textContent = 'Error';
            }
        }
        
        // Add message to conversation
        function addMessage(role, text) {
            if (!text) return;
            
            // Clear placeholder on first message
            if (conversationMessages.length === 0) {
                transcriptDisplay.textContent = '';
            }
            
            conversationMessages.push({ role, text });
            
            // Create message element
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;
            
            const labelDiv = document.createElement('div');
            labelDiv.className = 'message-label';
            labelDiv.textContent = role === 'user' ? 'You' : 'Assistant';
            
            const textDiv = document.createElement('div');
            textDiv.textContent = text;
            
            messageDiv.appendChild(labelDiv);
            messageDiv.appendChild(textDiv);
            
            transcriptDisplay.appendChild(messageDiv);
            
            // Scroll to bottom
            transcriptDisplay.scrollTop = transcriptDisplay.scrollHeight;
        }
        
        // Handle state updates
        function handleStateUpdate(state) {
            if (state.state) {
                updateStateDisplay(state.state);
            }
            vadProb.textContent = state.smoothed_prob.toFixed(3);
            segmentCount.textContent = state.segments_count;
        }
        
        // Update state display
        function updateStateDisplay(state) {
            const stateConfig = {
                quiet: { emoji: 'ðŸ”‡', text: 'QUIET' },
                starting: { emoji: 'ðŸŽ¤', text: 'STARTING' },
                speaking: { emoji: 'ðŸ—£ï¸', text: 'SPEAKING' },
                stopping: { emoji: 'â¹ï¸', text: 'STOPPING' },
                processing: { emoji: 'ðŸ¤”', text: 'PROCESSING' }
            };
            
            const config = stateConfig[state] || stateConfig.quiet;
            stateDisplay.textContent = `${config.emoji} ${config.text}`;
            stateDisplay.className = `state ${state}`;
        }
        
        // Start listening
        async function startListening() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: { 
                        sampleRate: 16000, 
                        channelCount: 1,
                        echoCancellation: false,
                        noiseSuppression: false
                    }
                });
                
                audioContext = new AudioContext({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(stream);
                const processor = audioContext.createScriptProcessor(512, 1, 1);
                
                processor.onaudioprocess = (e) => {
                    if (ws?.readyState !== WebSocket.OPEN) return;
                    
                    // Don't send audio while bot is speaking
                    if (audioPlayer && !audioPlayer.paused) {
                        return;
                    }
                    
                    const samples = e.inputBuffer.getChannelData(0);
                    const buffer = new Float32Array(samples);
                    
                    ws.send(buffer.buffer);
                };
                
                source.connect(processor);
                processor.connect(audioContext.destination);
                
                isListening = true;
                
                if (ws?.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({ type: "start_listening" }));
                }
                
                startBtn.textContent = 'Stop Listening';
                startBtn.className = 'stop';
                startBtn.onclick = stopListening;
                
                console.log('Microphone started');
                
            } catch (error) {
                alert('Microphone access required');
                console.error('Microphone error:', error);
            }
        }
        
        // Stop listening
        function stopListening() {
            isListening = false;
            
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            if (ws?.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: "stop_listening" }));
            }
            
            startBtn.textContent = 'Start Listening';
            startBtn.className = 'start';
            startBtn.onclick = startListening;
            
            console.log('Microphone stopped');
        }
        
        // Reset system
        function reset() {
            if (isListening) {
                stopListening();
            }
            
            if (ws?.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: "reset" }));
            }
            
            // Reset UI
            vadProb.textContent = '0.000';
            segmentCount.textContent = '0';
            statusValue.textContent = 'Ready';
            updateStateDisplay('quiet');
            
            // Clear conversation
            conversationMessages = [];
            transcriptDisplay.innerHTML = '<em style="color: #999;">Start speaking to begin conversation...</em>';
            
            console.log('UI reset');
        }
        
        // Initialize
        startBtn.onclick = startListening;
        document.getElementById('resetBtn').onclick = reset;
        
        connect();
    </script>
</body>
</html>